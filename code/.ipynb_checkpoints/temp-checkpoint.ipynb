{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character:\n",
    "    def __init__(self, image, label, feature=None):\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "        self.feature = feature\n",
    "        \n",
    "\n",
    "def load_paths(dataset):\n",
    "    if dataset == \"train\" or dataset == \"test-seen\":\n",
    "        paths = [\"../data/template/seen\"]\n",
    "    elif dataset == \"test-unseen\":\n",
    "        paths = [\"../data/template/unseen\"]\n",
    "    else:\n",
    "        paths = [\"../data/template/seen\", \"../data/template/unseen\"]\n",
    "    return paths\n",
    "\n",
    "\n",
    "def load_labels(dataset):\n",
    "    if dataset == \"train\":\n",
    "        table = pd.read_csv(\"../data/train/labels.txt\", header=None, encoding='gb2312')\n",
    "        labels = [item[1] for item in table.values]\n",
    "    elif dataset == \"test-seen\":\n",
    "        table = pd.read_csv(\"../data/test/seen/labels.txt\", header=None, encoding='gb2312')\n",
    "        labels = [item[1] for item in table.values]\n",
    "    elif dataset == \"test-unseen\":\n",
    "        table = pd.read_csv(\"../data/test/unseen/labels.txt\", header=None, encoding='gb2312')\n",
    "        labels = [item[1] for item in table.values]\n",
    "    else:\n",
    "        table1 = pd.read_csv(\"../data/test/seen/labels.txt\", header=None, encoding='gb2312')\n",
    "        table2 = pd.read_csv(\"../data/test/unseen/labels.txt\", header=None, encoding='gb2312')\n",
    "        labels = [item[1] for item in table1.values] + [item[1] for item in table2.values]\n",
    "    return labels\n",
    "\n",
    "\n",
    "def load_test_data(dataset, labels):\n",
    "    if dataset == \"train\":\n",
    "        paths = [\"../data/train\"]\n",
    "        amount = 15020\n",
    "    elif dataset == \"test-seen\":\n",
    "        paths = [\"../data/test/seen\"]\n",
    "        amount = 10000\n",
    "    elif dataset == \"test-unseen\":\n",
    "        paths = [\"../data/test/unseen\"]\n",
    "        amount = 10000\n",
    "    else:\n",
    "        paths = [\"../data/test/seen\", \"../data/test/unseen\"]\n",
    "        amount = 10000\n",
    "        \n",
    "    character_list = []\n",
    "    cnt = 0\n",
    "    for path in paths:\n",
    "        for i in range(amount):\n",
    "            name = str(i).zfill(4)\n",
    "            image = cv2.imread(path + \"/\" + name + \".jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "            image = image[2:46, 2:46].reshape([44, 44, 1]) / 255.0\n",
    "            character = Character(image, labels[cnt])\n",
    "            character_list.append(character)\n",
    "            cnt += 1\n",
    "    return character_list\n",
    "        \n",
    "    \n",
    "def load_template_list(paths, sess, siamese):\n",
    "    template_list = []\n",
    "    for path in paths:\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith(\"jpg\"):\n",
    "                image = cv2.imread(path+\"/\"+file, cv2.IMREAD_GRAYSCALE)\n",
    "                image = image[2:46, 2:46].reshape([44, 44, 1]) / 255.0\n",
    "                label = file[0]\n",
    "                feature = sess.run(siamese.right_output, feed_dict={siamese.right: [image],\n",
    "                                                                    siamese.training: False})[0]\n",
    "                template = Character(image, label, feature)\n",
    "                template_list.append(template)\n",
    "    print(\"字符模板加载完成\")\n",
    "    print(\"字符模板总数为%d\"%len(template_list))\n",
    "    return template_list\n",
    "    \n",
    "    \n",
    "def predict(character_list, template_list, sess, siamese):\n",
    "    pred_characters = []\n",
    "    true_characters = []\n",
    "    for index, character in enumerate(character_list):\n",
    "        feature = sess.run(siamese.left_output, feed_dict={siamese.left: [character.image], siamese.training: False})\n",
    "        prediction = sess.run(y_, feed_dict={siamesemese.template_feature: template_list,\n",
    "                                             siamese.template_feature: [template.feature for template in template_list],\n",
    "                                               siamese.training: False})\n",
    "        min_list = heapq.nsmallest(10, range(len(prediction)), prediction.take)\n",
    "        pred_character = [template_list[item].label for item in min_list]\n",
    "        pred_characters.append(pred_character)\n",
    "        true_characters.append(character.label)\n",
    "\n",
    "        sys.stdout.write('\\r>> Testing image %d/%d' % (index + 1, 10000))\n",
    "        sys.stdout.flush()\n",
    "    time2 = time.time()\n",
    "    print(\"\\nUsing time:\", \"%.2f\" % (time2 - time1) + \"s\")\n",
    "    \n",
    "def calculate_accuracy(dataset, true_characters, pred_characters, train_time):\n",
    "    count_top1 = 0\n",
    "    count_top5 = 0\n",
    "    count_top10 = 0\n",
    "    if dataset == \"train\":\n",
    "        f = open(\"../result/result-train%d.txt\" % train_time, \"w+\")\n",
    "    elif dataset == \"test-seen\":\n",
    "        f = open(\"../result/result-test-seen%d.txt\" % train_time, \"w+\")\n",
    "    elif dataset == \"test-unseen\":\n",
    "        f = open(\"../result/result-test-unseen%d.txt\" % train_time, \"w+\")\n",
    "    elif dataset == \"test\":\n",
    "        f = open(\"../result/result-test%d.txt\" % train_time, \"w+\")\n",
    "        \n",
    "    for index, item in enumerate(true_characters):\n",
    "        temp = list(pred_characters[index])\n",
    "        if item in temp:\n",
    "            temp.remove(item)\n",
    "        print(item, pred_characters[index])\n",
    "        f.write(item+\",\"+\"\".join(temp[0:10])+\"\\n\")\n",
    "        if item == pred_characters[index][0]:\n",
    "            count_top1 += 1\n",
    "        if item in pred_characters[index][0:5]:\n",
    "            count_top5 += 1\n",
    "        if item in pred_characters[index][0:10]:\n",
    "            count_top10 += 1\n",
    "    print(\"top1 acc:\", count_top1 / len(true_characters))\n",
    "    print(\"top5 acc:\", count_top5 / len(true_characters))\n",
    "    print(\"top10 acc:\", count_top10 / len(true_characters))\n",
    "    f.close()\n",
    "    \n",
    "def test(siamese, sess, dataset=None):\n",
    "    # 根据测试的数据集加载对于的匹配模板\n",
    "    paths = load_paths(dataset)\n",
    "    template_list = load_template_list(paths, sess, siamese)\n",
    "    \n",
    "    labels = load_labels(dataset)\n",
    "    character_list = load_test_data(dataset, labels)\n",
    "    pred_characters, true_characters = predict(character_list, template_list, sess, siamese)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15020"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load_labels(\"train\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
